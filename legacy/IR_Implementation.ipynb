{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "os.environ[\"CURL_CA_BUNDLE\"]=\"\"\n",
    "import os\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bhdemirbilek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7ffW6MAuAi-",
    "outputId": "f4f4830c-b1b8-4756-c4c7-78fb00a23ba8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336384/4219757529.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models because of the following error (look up to see its traceback):\nFailed to import transformers.tokenization_utils because of the following error (look up to see its traceback):\n/lib/x86_64-linux-gnu/libcrypto.so.3: version `OPENSSL_3.0.0' not found (required by /home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/tokenizers.cpython-38-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py:2777\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2775'>2776</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2776'>2777</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2777'>2778</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/importlib/__init__.py?line=125'>126</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/importlib/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfile_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m PaddingStrategy, TensorType, add_end_docstrings\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenization_utils_base\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=27'>28</a>\u001b[0m     ENCODE_KWARGS_DOCSTRING,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=28'>29</a>\u001b[0m     ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=29'>30</a>\u001b[0m     INIT_TOKENIZER_DOCSTRING,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=30'>31</a>\u001b[0m     AddedToken,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=31'>32</a>\u001b[0m     BatchEncoding,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=32'>33</a>\u001b[0m     EncodedInput,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=33'>34</a>\u001b[0m     EncodedInputPair,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=34'>35</a>\u001b[0m     PreTokenizedInput,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=35'>36</a>\u001b[0m     PreTokenizedInputPair,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=36'>37</a>\u001b[0m     PreTrainedTokenizerBase,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=37'>38</a>\u001b[0m     TextInput,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=38'>39</a>\u001b[0m     TextInputPair,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=39'>40</a>\u001b[0m     TruncationStrategy,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:78\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=76'>77</a>\u001b[0m \u001b[39mif\u001b[39;00m is_tokenizers_available():\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=77'>78</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m AddedToken\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=78'>79</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Encoding \u001b[39mas\u001b[39;00m EncodingFast\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py:79\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=75'>76</a>\u001b[0m     CONTIGUOUS \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcontiguous\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=78'>79</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=79'>80</a>\u001b[0m     Tokenizer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=80'>81</a>\u001b[0m     Encoding,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=81'>82</a>\u001b[0m     AddedToken,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=82'>83</a>\u001b[0m     Regex,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=83'>84</a>\u001b[0m     NormalizedString,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=84'>85</a>\u001b[0m     PreTokenizedString,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=85'>86</a>\u001b[0m     Token,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=86'>87</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/__init__.py?line=87'>88</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenizers\u001b[39;00m \u001b[39mimport\u001b[39;00m decoders\n",
      "\u001b[0;31mImportError\u001b[0m: /lib/x86_64-linux-gnu/libcrypto.so.3: version `OPENSSL_3.0.0' not found (required by /home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/tokenizers.cpython-38-x86_64-linux-gnu.so)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py:2777\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2775'>2776</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2776'>2777</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2777'>2778</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/importlib/__init__.py?line=125'>126</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/importlib/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=15'>16</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=16'>17</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=19'>20</a>\u001b[0m     albert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=20'>21</a>\u001b[0m     auto,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=21'>22</a>\u001b[0m     bart,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=22'>23</a>\u001b[0m     barthez,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=23'>24</a>\u001b[0m     bartpho,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=24'>25</a>\u001b[0m     beit,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=25'>26</a>\u001b[0m     bert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=26'>27</a>\u001b[0m     bert_generation,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=27'>28</a>\u001b[0m     bert_japanese,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=28'>29</a>\u001b[0m     bertweet,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=29'>30</a>\u001b[0m     big_bird,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=30'>31</a>\u001b[0m     bigbird_pegasus,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=31'>32</a>\u001b[0m     blenderbot,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=32'>33</a>\u001b[0m     blenderbot_small,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=33'>34</a>\u001b[0m     bort,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=34'>35</a>\u001b[0m     byt5,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=35'>36</a>\u001b[0m     camembert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=36'>37</a>\u001b[0m     canine,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=37'>38</a>\u001b[0m     clip,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=38'>39</a>\u001b[0m     convbert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=39'>40</a>\u001b[0m     convnext,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=40'>41</a>\u001b[0m     cpm,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=41'>42</a>\u001b[0m     ctrl,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=42'>43</a>\u001b[0m     data2vec,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=43'>44</a>\u001b[0m     deberta,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=44'>45</a>\u001b[0m     deberta_v2,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=45'>46</a>\u001b[0m     deit,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=46'>47</a>\u001b[0m     detr,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=47'>48</a>\u001b[0m     dialogpt,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=48'>49</a>\u001b[0m     distilbert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=49'>50</a>\u001b[0m     dpr,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=50'>51</a>\u001b[0m     electra,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=51'>52</a>\u001b[0m     encoder_decoder,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=52'>53</a>\u001b[0m     flaubert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=53'>54</a>\u001b[0m     fnet,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=54'>55</a>\u001b[0m     fsmt,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=55'>56</a>\u001b[0m     funnel,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=56'>57</a>\u001b[0m     gpt2,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=57'>58</a>\u001b[0m     gpt_neo,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=58'>59</a>\u001b[0m     gptj,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=59'>60</a>\u001b[0m     herbert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=60'>61</a>\u001b[0m     hubert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=61'>62</a>\u001b[0m     ibert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=62'>63</a>\u001b[0m     imagegpt,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=63'>64</a>\u001b[0m     layoutlm,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=64'>65</a>\u001b[0m     layoutlmv2,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=65'>66</a>\u001b[0m     layoutxlm,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=66'>67</a>\u001b[0m     led,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=67'>68</a>\u001b[0m     longformer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=68'>69</a>\u001b[0m     luke,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=69'>70</a>\u001b[0m     lxmert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=70'>71</a>\u001b[0m     m2m_100,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=71'>72</a>\u001b[0m     marian,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=72'>73</a>\u001b[0m     maskformer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=73'>74</a>\u001b[0m     mbart,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=74'>75</a>\u001b[0m     mbart50,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=75'>76</a>\u001b[0m     megatron_bert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=76'>77</a>\u001b[0m     megatron_gpt2,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=77'>78</a>\u001b[0m     mluke,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=78'>79</a>\u001b[0m     mmbt,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=79'>80</a>\u001b[0m     mobilebert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=80'>81</a>\u001b[0m     mpnet,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=81'>82</a>\u001b[0m     mt5,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=82'>83</a>\u001b[0m     nystromformer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=83'>84</a>\u001b[0m     openai,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=84'>85</a>\u001b[0m     pegasus,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=85'>86</a>\u001b[0m     perceiver,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=86'>87</a>\u001b[0m     phobert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=87'>88</a>\u001b[0m     plbart,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=88'>89</a>\u001b[0m     poolformer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=89'>90</a>\u001b[0m     prophetnet,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=90'>91</a>\u001b[0m     qdqbert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=91'>92</a>\u001b[0m     rag,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=92'>93</a>\u001b[0m     realm,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=93'>94</a>\u001b[0m     reformer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=94'>95</a>\u001b[0m     rembert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=95'>96</a>\u001b[0m     retribert,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=96'>97</a>\u001b[0m     roberta,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=97'>98</a>\u001b[0m     roformer,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=98'>99</a>\u001b[0m     segformer,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=99'>100</a>\u001b[0m     sew,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=100'>101</a>\u001b[0m     sew_d,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=101'>102</a>\u001b[0m     speech_encoder_decoder,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=102'>103</a>\u001b[0m     speech_to_text,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=103'>104</a>\u001b[0m     speech_to_text_2,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=104'>105</a>\u001b[0m     splinter,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=105'>106</a>\u001b[0m     squeezebert,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=106'>107</a>\u001b[0m     swin,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=107'>108</a>\u001b[0m     t5,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=108'>109</a>\u001b[0m     tapas,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=109'>110</a>\u001b[0m     transfo_xl,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=110'>111</a>\u001b[0m     trocr,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=111'>112</a>\u001b[0m     unispeech,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=112'>113</a>\u001b[0m     unispeech_sat,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=113'>114</a>\u001b[0m     vilt,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=114'>115</a>\u001b[0m     vision_encoder_decoder,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=115'>116</a>\u001b[0m     vision_text_dual_encoder,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=116'>117</a>\u001b[0m     visual_bert,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=117'>118</a>\u001b[0m     vit,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=118'>119</a>\u001b[0m     vit_mae,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=119'>120</a>\u001b[0m     wav2vec2,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=120'>121</a>\u001b[0m     wav2vec2_phoneme,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=121'>122</a>\u001b[0m     wav2vec2_with_lm,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=122'>123</a>\u001b[0m     wavlm,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=123'>124</a>\u001b[0m     xglm,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=124'>125</a>\u001b[0m     xlm,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=125'>126</a>\u001b[0m     xlm_prophetnet,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=126'>127</a>\u001b[0m     xlm_roberta,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=127'>128</a>\u001b[0m     xlm_roberta_xl,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=128'>129</a>\u001b[0m     xlnet,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=129'>130</a>\u001b[0m     yoso,\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/__init__.py?line=130'>131</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _LazyModule, is_tf_available, is_tokenizers_available, is_torch_available\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfiguration_layoutlm\u001b[39;00m \u001b[39mimport\u001b[39;00m LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP, LayoutLMConfig\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/__init__.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenization_layoutlm\u001b[39;00m \u001b[39mimport\u001b[39;00m LayoutLMTokenizer\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/configuration_layoutlm.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/configuration_layoutlm.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, List, Mapping, Optional\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/configuration_layoutlm.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m PretrainedConfig, PreTrainedTokenizer, TensorType\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/layoutlm/configuration_layoutlm.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m is_torch_available\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1039\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py:2767\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2765'>2766</a>\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2766'>2767</a>\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2767'>2768</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py:2779\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2777'>2778</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2778'>2779</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2779'>2780</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2780'>2781</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.tokenization_utils because of the following error (look up to see its traceback):\n/lib/x86_64-linux-gnu/libcrypto.so.3: version `OPENSSL_3.0.0' not found (required by /home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/tokenizers.cpython-38-x86_64-linux-gnu.so)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/bhdemirbilek/Documents/WS/WS_PY/public/DifferentiableSearchIndexAndRetrieval/IR_Implementation.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bhdemirbilek/Documents/WS/WS_PY/public/DifferentiableSearchIndexAndRetrieval/IR_Implementation.ipynb#ch0000002?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bhdemirbilek/Documents/WS/WS_PY/public/DifferentiableSearchIndexAndRetrieval/IR_Implementation.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bhdemirbilek/Documents/WS/WS_PY/public/DifferentiableSearchIndexAndRetrieval/IR_Implementation.ipynb#ch0000002?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bhdemirbilek/Documents/WS/WS_PY/public/DifferentiableSearchIndexAndRetrieval/IR_Implementation.ipynb#ch0000002?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bhdemirbilek/Documents/WS/WS_PY/public/DifferentiableSearchIndexAndRetrieval/IR_Implementation.ipynb#ch0000002?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloggers\u001b[39;00m \u001b[39mimport\u001b[39;00m WandbLogger\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/__init__.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=26'>27</a>\u001b[0m     _logger\u001b[39m.\u001b[39maddHandler(logging\u001b[39m.\u001b[39mStreamHandler())\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=27'>28</a>\u001b[0m     _logger\u001b[39m.\u001b[39mpropagate \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=30'>31</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningDataModule, LightningModule  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/__init__.py?line=31'>32</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer  \u001b[39m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=11'>12</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m Callback\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdevice_stats_monitor\u001b[39;00m \u001b[39mimport\u001b[39;00m DeviceStatsMonitor\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/__init__.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mearly_stopping\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m Optimizer\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=23'>24</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m STEP_OUTPUT\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=27'>28</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCallback\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=28'>29</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=29'>30</a>\u001b[0m \u001b[39m    Abstract base class used to build new callbacks.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=30'>31</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=31'>32</a>\u001b[0m \u001b[39m    Subclass this class and override any of the relevant hooks\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/base.py?line=32'>33</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/utilities/types.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/utilities/types.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m Optimizer\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/utilities/types.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/utilities/types.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m Metric\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/utilities/types.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Protocol, runtime_checkable\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/utilities/types.py?line=28'>29</a>\u001b[0m _NUMBER \u001b[39m=\u001b[39m Union[\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=10'>11</a>\u001b[0m _PACKAGE_ROOT \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m)\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=11'>12</a>\u001b[0m _PROJECT_ROOT \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(_PACKAGE_ROOT)\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m functional  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maggregation\u001b[39;00m \u001b[39mimport\u001b[39;00m CatMetric, MaxMetric, MeanMetric, MinMetric, SumMetric  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: E402\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=16'>17</a>\u001b[0m     PermutationInvariantTraining,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=17'>18</a>\u001b[0m     ScaleInvariantSignalDistortionRatio,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=20'>21</a>\u001b[0m     SignalNoiseRatio,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/__init__.py?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=11'>12</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpit\u001b[39;00m \u001b[39mimport\u001b[39;00m permutation_invariant_training, pit_permutate\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msdr\u001b[39;00m \u001b[39mimport\u001b[39;00m scale_invariant_signal_distortion_ratio, signal_distortion_ratio\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/__init__.py?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnr\u001b[39;00m \u001b[39mimport\u001b[39;00m scale_invariant_signal_noise_ratio, signal_noise_ratio\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright The PyTorch Lightning team.\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=11'>12</a>\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpit\u001b[39;00m \u001b[39mimport\u001b[39;00m permutation_invariant_training, pit_permutate  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msdr\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=15'>16</a>\u001b[0m     scale_invariant_signal_distortion_ratio,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=16'>17</a>\u001b[0m     signal_distortion_ratio,\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=17'>18</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msnr\u001b[39;00m \u001b[39mimport\u001b[39;00m scale_invariant_signal_noise_ratio, signal_noise_ratio  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py?line=17'>18</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimports\u001b[39;00m \u001b[39mimport\u001b[39;00m _SCIPY_AVAILABLE\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py?line=22'>23</a>\u001b[0m \u001b[39m# _ps_dict: cache of permutations\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py?line=23'>24</a>\u001b[0m \u001b[39m# it's necessary to cache it, otherwise it will consume a large amount of time\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/functional/audio/pit.py?line=24'>25</a>\u001b[0m _ps_dict: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m {}  \u001b[39m# _ps_dict[str(spk_num)+str(device)] = permutations\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchecks\u001b[39;00m \u001b[39mimport\u001b[39;00m check_forward_full_state_property  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m apply_to_collection  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m \u001b[39mimport\u001b[39;00m class_reduce, reduce  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/checks.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/checks.py?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/checks.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/checks.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m select_topk, to_onehot\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/checks.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menums\u001b[39;00m \u001b[39mimport\u001b[39;00m DataType\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/checks.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_for_empty_tensors\u001b[39m(preds: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/data.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/data.py?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/data.py?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, tensor\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/data.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimports\u001b[39;00m \u001b[39mimport\u001b[39;00m _TORCH_GREATER_EQUAL_1_6, _TORCH_GREATER_EQUAL_1_7, _TORCH_GREATER_EQUAL_1_8\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/data.py?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m _TORCH_GREATER_EQUAL_1_8:\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/data.py?line=21'>22</a>\u001b[0m     deterministic \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mare_deterministic_algorithms_enabled\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py:120\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=117'>118</a>\u001b[0m _TQDM_AVAILABLE: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m _package_available(\u001b[39m\"\u001b[39m\u001b[39mtqdm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=118'>119</a>\u001b[0m _TRANSFORMERS_AVAILABLE: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m _package_available(\u001b[39m\"\u001b[39m\u001b[39mtransformers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=119'>120</a>\u001b[0m _TRANSFORMERS_AUTO_AVAILABLE \u001b[39m=\u001b[39m _module_available(\u001b[39m\"\u001b[39;49m\u001b[39mtransformers.models.auto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=120'>121</a>\u001b[0m _PESQ_AVAILABLE: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m _package_available(\u001b[39m\"\u001b[39m\u001b[39mpesq\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=121'>122</a>\u001b[0m _SACREBLEU_AVAILABLE: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m _package_available(\u001b[39m\"\u001b[39m\u001b[39msacrebleu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py:64\u001b[0m, in \u001b[0;36m_module_available\u001b[0;34m(module_path)\u001b[0m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=61'>62</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=62'>63</a>\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m module_names[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m---> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=63'>64</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(module, name):\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=64'>65</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/torchmetrics/utilities/imports.py?line=65'>66</a>\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py:2765\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2762'>2763</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objects[name]\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2763'>2764</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules:\n\u001b[0;32m-> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2764'>2765</a>\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(name)\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2765'>2766</a>\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2766'>2767</a>\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n",
      "File \u001b[0;32m~/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py:2779\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2776'>2777</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2777'>2778</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2778'>2779</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2779'>2780</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/file_utils.py?line=2780'>2781</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models because of the following error (look up to see its traceback):\nFailed to import transformers.tokenization_utils because of the following error (look up to see its traceback):\n/lib/x86_64-linux-gnu/libcrypto.so.3: version `OPENSSL_3.0.0' not found (required by /home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/tokenizers/tokenizers.cpython-38-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from nlp import load_metric\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AryYekz2DjA-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'./data_100K_clipped_documents_1k_words.csv',nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGrEZzoWD0Wp",
    "outputId": "c42a6201-c985-4746-c9fd-d56e41623ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records where doc_id is null 0\n"
     ]
    }
   ],
   "source": [
    "print('Records where doc_id is null',len(df[df['doc_id'].isna()==True]))\n",
    "doc_url_map = df[['doc_id','document_url']]\n",
    "df = df[['doc_id','document_text',  'question_text' ]]\n",
    "\n",
    "df['doc_id'] = df['doc_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tzi4E8rkuuFF",
    "outputId": "4dc292b5-49ae-4ceb-a3bf-1ff460e7d7c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DS5b-EipPjiI"
   },
   "outputs": [],
   "source": [
    "data_len = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSmvHdBD8Jhi"
   },
   "source": [
    "# Data Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ds35Tn742BmF"
   },
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"\n",
    "token_len = 512\n",
    "model_prefix = f\"{model_name}-{token_len}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6ZefRJsR6ZYm"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def chunk(indices, chunk_size):\n",
    "    return torch.split(torch.tensor(indices), chunk_size)\n",
    "\n",
    "class Sampler():\n",
    "    def __init__(self, index_lists,batch_size):\n",
    "        '''\n",
    "        The description of the args is as below:\n",
    "            index_lists is a list of lists of indexes. eg. [[1,2,3,4],[5,6,7,8]]\n",
    "            batch_size is the size of the batches that need to be created.\n",
    "        '''\n",
    "        self.index_lists = index_lists\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        '''\n",
    "        This function creates batches of indexes.\n",
    "        For each list in the index_list, the batch is created.\n",
    "        eg. index_list = [[1,2,3,4],[5,6,7,8]], batch_size = 2\n",
    "            the result batches will be [(1,2),(3,4),(5,6),(7,8)]\n",
    "        '''\n",
    "\n",
    "        index_lists = copy.deepcopy(self.index_lists)       \n",
    "        res = []\n",
    "        for cl in index_lists:\n",
    "            random.shuffle(cl)\n",
    "            gp = chunk(cl, self.batch_size)\n",
    "            for j in gp:\n",
    "                res.append(j.tolist())\n",
    "\n",
    "\n",
    "        return iter(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wC9RYBsZbOdD"
   },
   "outputs": [],
   "source": [
    "class NQData(Dataset):\n",
    "    # task_type is either 'indexing' or 'retrival' or 'indexing_retrival'\n",
    "    def __init__(self, df, tokenizer, type_path, num_samples, task_type,input_length=4096,\n",
    "                 output_length=4096, print_text=False):         \n",
    "        \n",
    "        ## Shuffle data set\n",
    "        df = df.sample(frac=1, random_state=1)\n",
    "        self.dataset = []\n",
    "        self.task_type = task_type\n",
    "        self.indexing_task_name = 'indexing'\n",
    "        self.retrival_task_name ='retrival'\n",
    "        self.retrival_str_max_len = 20\n",
    " \n",
    "        self.indexing_str_max_len = output_length\n",
    "        \n",
    "        sep = int(len(self.dataset)/2)\n",
    "   \n",
    "        \n",
    "        val_size = int(0.2 * len(df))\n",
    "        \n",
    "\n",
    "        if task_type == self.indexing_task_name:\n",
    "           \n",
    "            self.indices = [[]]\n",
    "   \n",
    "            self.dataset = self.get_dataset_list(data=df,\n",
    "                                                    type_path=type_path,\n",
    "                                                    col='document_text',\n",
    "                                                    task_name=self.indexing_task_name,\n",
    "                                                    split_size=val_size,\n",
    "                                                    splits=True\n",
    "                                                )\n",
    "            self.indices[0].extend(list(range(len(self.dataset))))\n",
    "\n",
    "        elif task_type == self.retrival_task_name:\n",
    "            \n",
    "            self.indices = [[]]\n",
    "            self.dataset = self.get_dataset_list(data=df,\n",
    "                                                    type_path=type_path,\n",
    "                                                    col='question_text',\n",
    "                                                    task_name=self.indexing_task_name,\n",
    "                                                    split_size=val_size,\n",
    "                                                    splits=True\n",
    "                                                 )\n",
    "            self.indices[0].extend(list(range(len(self.dataset))))\n",
    "\n",
    "        elif task_type == 'indexing_retrival':\n",
    "            inp_cols = ['document_text','question_text']\n",
    "            self.indices = [[] for _ in range(len(inp_cols))]\n",
    "           \n",
    "            for idx, col in enumerate(inp_cols):\n",
    "                length = len(self.dataset)\n",
    "\n",
    "                if col == 'document_text':\n",
    "                                   \n",
    "                    dataset = self.get_dataset_list(data=df,\n",
    "                                                    type_path=type_path,\n",
    "                                                    col=col,\n",
    "                                                    task_name=self.indexing_task_name,\n",
    "                                                    split_size=val_size,\n",
    "                                                    splits=False)\n",
    "                else:\n",
    "                    \n",
    "                    dataset = self.get_dataset_list(data=df,\n",
    "                                                    type_path=type_path,\n",
    "                                                    col=col,\n",
    "                                                    task_name=self.retrival_task_name,\n",
    "                                                    split_size=val_size,\n",
    "                                                    splits=True)\n",
    "                \n",
    "                self.dataset.extend(dataset)\n",
    "                \n",
    "             \n",
    "                self.indices[idx].extend(list(range(length, len(self.dataset) )))\n",
    "\n",
    "        if num_samples:\n",
    "            self.dataset = self.dataset[:num_samples]\n",
    "        \n",
    "      \n",
    "\n",
    "        self.input_length = input_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_length = output_length\n",
    "        self.print_text = print_text\n",
    "\n",
    "    def get_dataset_list(self,data,type_path,col,task_name,split_size,splits):\n",
    "\n",
    "       \n",
    "        dataset = []  \n",
    "        \n",
    "        d1 = data[[col,'doc_id']]\n",
    "        \n",
    "        if splits :\n",
    "            if type_path == \"train\":\n",
    "                d1 = d1.iloc[split_size :]\n",
    "            else:\n",
    "                d1 = d1.iloc[:split_size]\n",
    "        \n",
    "        d1[col] = task_name +': ' + d1[col]\n",
    "\n",
    "        d1.columns = ['inp','lbl']\n",
    "        dataset.extend(d1.to_dict(orient='records'))  \n",
    "        return dataset\n",
    "\n",
    "    def get_index_list(self):\n",
    "        \n",
    "        return self.indices\n",
    "        \n",
    "  \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def convert_to_features(self, example_batch):\n",
    "       \n",
    "        \n",
    "        input_ = example_batch['inp']\n",
    "        target_ = example_batch['lbl']\n",
    "        if example_batch['inp'].startswith(self.retrival_task_name):\n",
    "            max_length = self.retrival_str_max_len\n",
    "        else:\n",
    "            max_length = self.indexing_str_max_len\n",
    "        \n",
    "        input_ = input_.strip()\n",
    "\n",
    "        \n",
    "        source = self.tokenizer.batch_encode_plus([input_], max_length= max_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        targets = self.tokenizer.batch_encode_plus([target_], max_length=3, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return source, targets\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "      \n",
    "\n",
    "        source, targets = self.convert_to_features(self.dataset[index])\n",
    "        \n",
    "        \n",
    "        \n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        target_ids = targets[\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        target_mask = targets[\"attention_mask\"].squeeze()\n",
    "\n",
    "        if self.print_text:\n",
    "            print(\"Lens are: \", source['input_ids'][0].shape, targets['input_ids'][0].shape)\n",
    "           \n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(tokenizer, type_path, num_samples, task_type, args, df=df):\n",
    "      return NQData(df=df, tokenizer=tokenizer, type_path=type_path, num_samples=num_samples, \n",
    "                    task_type=task_type, input_length=args.max_input_length, \n",
    "                        output_length=args.max_output_length)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "5xB10ree4bgq"
   },
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix((remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "dcAtHQGw7uei"
   },
   "outputs": [],
   "source": [
    "def exact_match_score(prediction, ground_truth):\n",
    "    #print(\"exact match score\")\n",
    "    #print(prediction)\n",
    "    #print(ground_truth)\n",
    "    #print(int(normalize_answer(prediction) == normalize_answer(ground_truth)))\n",
    "    #exit(0)\n",
    "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "647gTbanJcIc"
   },
   "outputs": [],
   "source": [
    "def calculate_scores(predictions, ground_truths):\n",
    "    em_score = 0\n",
    "    subset_match_score = 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        ground_truth = ground_truths[i]\n",
    "        prediction = predictions[i]\n",
    "        em_score +=  exact_match_score(prediction, ground_truth)\n",
    "    \n",
    "    em_score /= len(predictions)\n",
    "    #print(len(predictions))\n",
    "    return em_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "9Gve5Z5GWniZ"
   },
   "outputs": [],
   "source": [
    "def save_metrics(save_path, epoch_metric_val_tuple, metric_name):\n",
    "   \n",
    "    if os.path.exists(save_path):\n",
    "        header = False\n",
    "    else:\n",
    "        header = True\n",
    "    \n",
    "    tmp = pd.DataFrame([epoch_metric_val_tuple], columns=['epoch','value'])\n",
    "    tmp['metric'] = metric_name\n",
    "    tmp['timestamp'] = datetime.now()\n",
    "    tmp.to_csv(save_path, mode='a',header=header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "j9iEDixFJkV9"
   },
   "outputs": [],
   "source": [
    "class NQ_IR(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(NQ_IR, self).__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path, return_dict=True)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path, max_length=hparams.max_input_length)\n",
    "        self.output_dir = Path(self.hparams.output_dir)\n",
    "        self.step_count = 0\n",
    "\n",
    "        # https://github.com/huggingface/transformers/blob/main/examples/legacy/seq2seq/finetune_trainer.py\n",
    "        if self.hparams.freeze_embeds:\n",
    "            self.freeze_embeds()\n",
    "        if self.hparams.freeze_encoder:\n",
    "            self.freeze_params(self.model.get_encoder())\n",
    "           \n",
    "            \n",
    "        n_observations_per_split = {\n",
    "            \"train\": self.hparams.n_train,\n",
    "            \"validation\": self.hparams.n_val,\n",
    "            \"test\": self.hparams.n_test,\n",
    "        }\n",
    "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
    "        self.em_score_list = []\n",
    " \n",
    "        \n",
    "    def freeze_params(self, model):\n",
    "        for par in model.parameters():\n",
    "            par.requires_grad = False\n",
    "            \n",
    "    def freeze_embeds(self):\n",
    "        try:\n",
    "            self.freeze_params(self.model.model.shared)\n",
    "            for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "                freeze_params(d.embed_positions)\n",
    "                freeze_params(d.embed_tokens)\n",
    "        except AttributeError:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "\n",
    "    def lmap(self, f, x):\n",
    "        return list(map(f, x))\n",
    "\n",
    "    def is_logger(self):\n",
    "        return self.trainer.global_rank <= 0\n",
    "    \n",
    "    def parse_score(self, result):\n",
    "        return {k: round(v.mid.fmeasure * 100, 4) for k, v in result.items()}\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None):\n",
    "        \n",
    "        return self.model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                decoder_input_ids=decoder_input_ids,\n",
    "                decoder_attention_mask=decoder_attention_mask,\n",
    "                labels=lm_labels\n",
    "            )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        labels = batch[\"target_ids\"]\n",
    "        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def ids_to_clean_text(self, generated_ids):\n",
    "        gen_text = self.tokenizer.batch_decode(\n",
    "            generated_ids,\n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        #print(\"gen_text: \", gen_text)\n",
    "        return self.lmap(str.strip, gen_text)\n",
    "    \n",
    "    def _generative_step(self, batch) :\n",
    "        \n",
    "        t0 = time.time()\n",
    "        # print(batch)\n",
    "        inp_ids = batch[\"source_ids\"]\n",
    "        \n",
    "        generated_ids = self.model.generate(\n",
    "            batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            use_cache=True,\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            max_length=3\n",
    "\n",
    "        )\n",
    "        preds = self.ids_to_clean_text(generated_ids)\n",
    "        target = self.ids_to_clean_text(batch[\"target_ids\"])\n",
    "        \n",
    "            \n",
    "        gen_time = (time.time() - t0) / batch[\"source_ids\"].shape[0]  \n",
    "    \n",
    "        loss = self._step(batch)\n",
    "        base_metrics = {'val_loss': loss}\n",
    "        summ_len = np.mean(self.lmap(len, generated_ids))\n",
    "        base_metrics.update(gen_time=gen_time, gen_len=summ_len, preds=preds, target=target)\n",
    "        em_score  = calculate_scores(preds, target)\n",
    "        \n",
    "        self.em_score_list.append(em_score)\n",
    "        \n",
    "        em_score = torch.tensor(em_score,dtype=torch.float32)\n",
    "    \n",
    "        base_metrics.update(accuracy=em_score)\n",
    "        \n",
    "        return base_metrics\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "\n",
    "        # the below returned dictionary is accessed in the train_epoch_end method\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "  \n",
    "    def training_epoch_end(self, outputs):\n",
    "       \n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "       \n",
    "        self.log(\"avg_train_loss\", avg_train_loss)\n",
    "\n",
    "        train_losses = (self.trainer.current_epoch,avg_train_loss.item())\n",
    "        save_metrics(save_path=self.hparams.log_dir, epoch_metric_val_tuple=train_losses, metric_name='train_losses')\n",
    "\n",
    "        lr_vals = (self.trainer.current_epoch,self.lr_scheduler.get_last_lr()[-1])\n",
    "        save_metrics(save_path=self.hparams.log_dir, epoch_metric_val_tuple=lr_vals, metric_name='lr')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._generative_step(batch)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        # tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "        \n",
    "        if len(self.em_score_list) <= 2:\n",
    "            average_em_score = sum(self.em_score_list) / len(self.em_score_list) \n",
    "            \n",
    "        else:\n",
    "            latest_em_score = self.em_score_list[:-2]\n",
    "            average_em_score = sum(latest_em_score) / len(latest_em_score) \n",
    "        \n",
    "        average_em_score = torch.tensor(average_em_score,dtype=torch.float32)\n",
    "        # tensorboard_logs.update(accuracy=average_em_score)\n",
    "        \n",
    "        self.target_gen= []\n",
    "        self.prediction_gen=[]\n",
    "\n",
    "        # self.log creates the lightening folder and stores the logs. \n",
    "        # This self.log dict is used by the ModelCheckpoint for find the model that fits the checking criteria.\n",
    "        # So in ModelCheckpointing, if moniter= 'avg_val_loss' and  mode='min' then the 'avg_val_loss' in the self.loss is looked at to get model with min avg_val_loss\n",
    "        self.log(\"avg_val_loss\", avg_loss) \n",
    "        self.log(\"val_accuracy\" , average_em_score)\n",
    "\n",
    "        val_losses = (self.trainer.current_epoch,avg_loss.item())\n",
    "        save_metrics(save_path=self.hparams.log_dir, epoch_metric_val_tuple=val_losses, metric_name='val_losses')\n",
    "\n",
    "        val_accuracies = (self.trainer.current_epoch,average_em_score.item())\n",
    "        save_metrics(save_path=self.hparams.log_dir, epoch_metric_val_tuple=val_accuracies, metric_name='val_accuracies')\n",
    "        # self.val_losses.append((self.trainer.current_epoch,avg_loss.item()))\n",
    "        # self.val_accuracies.append((self.trainer.current_epoch,average_em_score.item()))\n",
    "\n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "  \n",
    "  \n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "    \n",
    "    def train_dataloader(self):   \n",
    "        \n",
    "        n_samples = self.n_obs['train']\n",
    "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\",task_type ='indexing_retrival', num_samples=n_samples, args=self.hparams)\n",
    "        dataloader = DataLoader(train_dataset,\n",
    "                                batch_sampler=Sampler(train_dataset.get_index_list(),self.hparams.train_batch_size),\n",
    "                                num_workers=8\n",
    "                                )\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "            // self.hparams.gradient_accumulation_steps\n",
    "            * float(self.hparams.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        n_samples = self.n_obs['validation']\n",
    "        validation_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"validation\",task_type ='indexing_retrival', num_samples=n_samples, args=self.hparams)\n",
    "        \n",
    "        return DataLoader(validation_dataset, \n",
    "                          batch_sampler=Sampler(validation_dataset.get_index_list(),self.hparams.eval_batch_size),num_workers=8)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        n_samples = self.n_obs['test']\n",
    "        test_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"test\",task_type ='retrival', num_samples=n_samples, args=self.hparams)\n",
    "        \n",
    "        return DataLoader(test_dataset, \n",
    "                          batch_sampler=Sampler(test_dataset.get_index_list(),self.hparams.eval_batch_size),\n",
    "                          num_workers=2)\n",
    "    \n",
    "    # def on_save_checkpoint(self, checkpoint):\n",
    "    #     save_path = self.output_dir.joinpath(model_prefix)\n",
    "    #     self.model.config.save_step = self.step_count\n",
    "    #     self.model.save_pretrained(save_path)\n",
    "    #     self.tokenizer.save_pretrained(save_path)\n",
    "\n",
    "    def test_model(self, batch) :\n",
    "        \n",
    "        inp_ids = batch[\"source_ids\"]\n",
    "        \n",
    "        generated_ids = self.model.generate(\n",
    "            batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            use_cache=True,\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            max_length=3\n",
    "\n",
    "        )\n",
    "        preds = self.ids_to_clean_text(generated_ids)\n",
    "        target = self.ids_to_clean_text(batch[\"target_ids\"])\n",
    "        \n",
    "        \n",
    "        #print(generated_ids, generated_ids.shape)\n",
    "        #print(preds)\n",
    "        print(batch[\"target_ids\"])\n",
    "        \n",
    "\n",
    "        em_score  = calculate_scores(preds, target)\n",
    "    \n",
    "        return em_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tW-sGf1dI5c0",
    "outputId": "368ac9cc-3d08-4866-bcea-49e9103b79d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./t5-small-512_50000_rows_checkpoint/epoch=0-step=2047.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "checkpoints_dir = './t5-small-512_50000_rows_checkpoint/'\n",
    "checkpoint_files = os.listdir(checkpoints_dir)\n",
    "\n",
    "if len(checkpoint_files)==0:\n",
    "    resume_from_checkpoint_path = None\n",
    "    raise Exception('No checkpoint found')\n",
    "\n",
    "else:\n",
    "    resume_from_checkpoint_path = checkpoints_dir  + checkpoint_files[-1]\n",
    "\n",
    "print(resume_from_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvx1quVaJvio",
    "outputId": "3bee1347-7ea8-4ea6-c0ab-2382b9df56c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file path: ./logs/log_t5-small-512_50000_rows_2022_05_29_20_31_40.csv\n"
     ]
    }
   ],
   "source": [
    "#log_dir = \"./logs/log_t5-small-512_50000_rows_2022_05_01_13_07_19.csv\"\n",
    "log_dir = \"./logs/log_t5-small-512_50000_rows_\"+datetime.today().strftime('%Y_%m_%d_%H_%M_%S')+\".csv\"\n",
    "print('Log file path:', log_dir)\n",
    "\n",
    "args_dict = dict(\n",
    "    output_dir=f\"./{model_prefix}_{str(data_len)}_rows_final\", # path to save the checkpoints\n",
    "    log_dir = log_dir,\n",
    "    model_name_or_path=model_name,\n",
    "    tokenizer_name_or_path=model_name,\n",
    "    max_input_length=token_len,\n",
    "    max_output_length=token_len,\n",
    "    freeze_encoder=False,\n",
    "    freeze_embeds=False,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=1,\n",
    "    eval_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    n_gpu=1,\n",
    "    resume_from_checkpoint_path=resume_from_checkpoint_path, \n",
    "    val_check_interval = 1, \n",
    "    check_val_every_n_epoch = 1,\n",
    "    n_val=-1,\n",
    "    n_train=-1,\n",
    "    n_test=-1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    # opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "\n",
    "## Define Checkpoint function\n",
    "# monitor - monitors the metric and saves the chekpoint with the mode value. Here mode=max so saves the checkpoint with max metric value.\n",
    "# save_top_k saves lastest k checkpoints\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=f\"./{model_prefix}_{str(data_len)}_rows_checkpoint\", \n",
    "                                                    monitor=\"avg_val_loss\", mode=\"min\", save_top_k=1) \n",
    "\n",
    "\n",
    "# accumulate_grad_batches stores the gradients for a set of batches and then updates the model params. \n",
    "    # So if batch size=8 and accumulate_grad_batches= 2 then the gradients are accumulated for 2 batches and the model params are updated only at the end of the 2nd batch.\n",
    "    # The default was to update the model params at the end of each batch\n",
    "\n",
    "train_params = dict(\n",
    "    # accumulate_grad_batches=args.gradient_accumulation_steps, # with this, total batchsize= batchsize* accumulate_grad_batches\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    check_val_every_n_epoch=args.check_val_every_n_epoch,\n",
    "    callbacks=[checkpoint_callback] ,  #[LoggingCallback()],\n",
    "\n",
    "    # logger=wandb_logger,\n",
    "    # val_check_interval=args.val_check_interval,\n",
    "    # amp_level=args.opt_level,\n",
    "    # resume_from_checkpoint=args.resume_from_checkpoint, # depreciated\n",
    "    # progress_bar_refresh_rate=0\n",
    "    # log_every_n_steps=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "EXw42MfUHvvo"
   },
   "outputs": [],
   "source": [
    "trainer_fit_params=dict(ckpt_path=args.resume_from_checkpoint_path, # to resume from this checkpoint\n",
    "                        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "276370695db3437a8e1df01ae1ce341a",
      "d908770a619543f98722c8fe6c606792",
      "870c08e73dec475a8eb870cb5de32740",
      "1d17a2de1427404ab91551cb63a63b40",
      "677b8b86db30437b80a0281d3780f632",
      "4e628e0681454e02855a088042c08bb0",
      "684f030cfcc44ce1a3621f0170860c4e",
      "89fc34e3829d46fb926bd16a3b1d82d3",
      "3734dfdad0164274a8c0b05b71a3ff77",
      "bc43b29e05c5492685a0454967fbcf7f",
      "51fda6fe16ac494598ff5cece064cb1f",
      "22548c8fe991408eb4dc440bf4c5fb35",
      "a3e208e979ee41aaaf30adc62a060f41",
      "2ef76ee0d4e44b53a275a24aeedc3b72",
      "d349cc4b57234cde9610f1cbc090a4c1",
      "607f07ee4e664ec5b100ddb298c6d91b",
      "d30c1e610bec44d7a95abc86783c0117",
      "e0798eb9ff0d4adda3001e992bf8207e",
      "442cc6d0066c4c44b66ff3edf269c855",
      "5f1936d1022d4f3ca1050c0edf98b8f1",
      "034a9440e5514d8c99b71344108ebf2d",
      "33552a1609e24bd69173b0302040534c",
      "6c7a83444b354148b147e5b2f0aa9c07",
      "092190e7dd5e459db9e5b4b774a02ec8",
      "ab6da49e288a4146a7b19b342df1f35a",
      "4d4eaef3d4144bd9b9a838bab9230255",
      "0607bc102e604876994c56479cc7ea2a",
      "0ec63a50fbd049269e9c4eecb152e2cf",
      "d0da1ea81e5a4959a4785c4411292361",
      "0998fb47b4844662aff81bf27b995d2d",
      "6b1608a2b9954388ab9ba24d360653ca",
      "7006a50675a34b24ad9271a84bd5bdc8",
      "37cea5acad284f3b962adaf6053b7232"
     ]
    },
    "id": "iMArid4IVKgs",
    "outputId": "c03e841e-fe79-44fc-915c-e182fac19de9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NQ_IR(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUvOQ9SRVLXk",
    "outputId": "88b32997-fcc8-4041-8a10-59df761383bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fc1846fbe50>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fc1846fbe50>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params, fast_dev_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419,
     "referenced_widgets": [
      "58c1590654a44b8f97f14b14a44fd436",
      "514a382acf2941c0af0a2844a6006b4f",
      "04b8a8c40cfc4eb4987af7f0e52736c2",
      "853e69d805a84f80bb3cd252eda0ad6e",
      "4eab4e2d5aee4a919f0817024fcc4b8b",
      "37fbea390a194f70ab4b9910f11c41cc",
      "acd520a4d97d4fc29e5445fd168a84dc",
      "30f45dd143564727b4c2859614795852",
      "bdecf506168f4d51847b928e23c0eb54",
      "8a32fe19d7784278bfd426d3114c8e24",
      "895dade65c4141bfb69dc491076827c3"
     ]
    },
    "id": "lS9wjtPsJ1JS",
    "outputId": "dbdd7061-6452-42d4-aa34-28d865fc9bca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/bhdemirbilek/Documents/WS_PY/public/Transformer_Memory_As_A_Differentiable_Search_Index/t5-small-512_50000_rows_checkpoint exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Restoring states from the checkpoint path at ./t5-small-512_50000_rows_checkpoint/epoch=0-step=2047.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint file at ./t5-small-512_50000_rows_checkpoint/epoch=0-step=2047.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44082/321847975.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d1[col] = task_name +': ' + d1[col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,**trainer_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host '10.1.200.207'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/bhdemirbilek/miniconda3/envs/dsi/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trained_model = NQ_IR.load_from_checkpoint(resume_from_checkpoint_path, hparams= args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1179, 3264,    1]])\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loader = trained_model.test_dataloader()\n",
    "i=0\n",
    "for batch in test_loader:\n",
    "\n",
    "    print(trained_model.test_model(batch))\n",
    "    #print(batch.shape)\n",
    "    #print(batch)\n",
    "    i+=1\n",
    "    if i==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pl.utilities.model_summary.ModelSummary(trained_model, max_depth=1) )\n",
    "print(pl.utilities.model_summary.ModelSummary(model, max_depth=1)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxJWuP9FJxgB",
    "outputId": "93e56776-ce9b-49f3-9a91-efd9636b1c1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4-BnoWWH1tp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ei98UVH7sa"
   },
   "outputs": [],
   "source": [
    "logs = pd.read_csv(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svh4ci1YJO32",
    "outputId": "307a96a3-d860-41a4-abe2-fdc416fd266b"
   },
   "outputs": [],
   "source": [
    "logs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "CATuMpHyeJ4n",
    "outputId": "ac40c376-85d7-4601-e783-1d30a153c766"
   },
   "outputs": [],
   "source": [
    "logs[logs['epoch']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7n0LrehnL6fv"
   },
   "outputs": [],
   "source": [
    "# In pytorch-lightning, the model first runs on the validation dataset, hence there'll be multiple validation logs for same epoch. \n",
    "# Below, we are removing the additional validation logs \n",
    "\n",
    "logs1 = pd.merge(logs[logs['metric']=='train_losses'][['epoch','timestamp']], \n",
    "                 logs[logs['metric']=='val_losses'],\n",
    "                 on=['epoch'],\n",
    "                 how='inner'\n",
    "                 )\n",
    "logs1['timestamp_x'] = logs1['timestamp_x'].astype('datetime64[s]').values.astype('<M8[m]')\n",
    "logs1['timestamp_y'] = logs1['timestamp_y'].astype('datetime64[s]').values.astype('<M8[m]')\n",
    "logs1 = logs1[logs1['timestamp_x']==logs1['timestamp_y']]\n",
    "logs1.drop(['timestamp_y'],axis=1, inplace=True)\n",
    "logs1.rename(columns={'timestamp_x':'timestamp'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_o9Py8VUsQT"
   },
   "outputs": [],
   "source": [
    "logs2 = pd.merge(logs[logs['metric']=='train_losses'][['epoch','timestamp']], \n",
    "                 logs[logs['metric']=='val_accuracies'],\n",
    "                 on=['epoch'],\n",
    "                 how='inner'\n",
    "                 )\n",
    "logs2['timestamp_x'] = logs2['timestamp_x'].astype('datetime64[s]').values.astype('<M8[m]')\n",
    "logs2['timestamp_y'] = logs2['timestamp_y'].astype('datetime64[s]').values.astype('<M8[m]')\n",
    "logs2 = logs2[logs2['timestamp_x']==logs2['timestamp_y']]\n",
    "logs2.drop(['timestamp_y'],axis=1, inplace=True)\n",
    "logs2.rename(columns={'timestamp_x':'timestamp'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYJcdC5nIEF_"
   },
   "outputs": [],
   "source": [
    "logs_val_losses = logs1[logs1['metric']=='val_losses'].sort_values(['epoch','timestamp']).drop_duplicates(['epoch'], keep='last')\n",
    "logs_val_accuracies = logs2[logs2['metric']=='val_accuracies'].sort_values(['epoch','timestamp']).drop_duplicates(['epoch'], keep='last')\n",
    "logs_train_losses = logs[logs['metric']=='train_losses']\n",
    "logs_lr = logs[logs['metric']=='lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "nbW9hd-hJaoC",
    "outputId": "87a6988a-277f-40b1-d512-bb559d916f67"
   },
   "outputs": [],
   "source": [
    "plt.plot(logs_val_accuracies['epoch'],logs_val_accuracies['value'],marker='o')\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "24jLgj06JtBI",
    "outputId": "b36f309b-b6cc-4443-e02a-0e5e0949dadb"
   },
   "outputs": [],
   "source": [
    "plt.plot(logs_val_losses['epoch'],logs_val_losses['value'],marker='o')\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "4Tv5WCDHJWak",
    "outputId": "22549d79-c9ba-439f-969a-7fb59e87bb75"
   },
   "outputs": [],
   "source": [
    "plt.plot(logs_train_losses['epoch'],logs_train_losses['value'],marker='o')\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "RKlSyWodWbGX",
    "outputId": "b811952f-fa01-4881-c0ae-75f727e50056"
   },
   "outputs": [],
   "source": [
    "plt.plot(logs_val_losses['epoch'],logs_val_losses['value'], c='red',marker='o', label = \"Validation Loss\")\n",
    "plt.plot(logs_train_losses['epoch'],logs_train_losses['value'], c='green',marker='o', label = \"Train Loss\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "YtEqHxHoJKxm",
    "outputId": "3a07d63c-d58f-4c9e-9a1c-27c5c95d7ddb"
   },
   "outputs": [],
   "source": [
    "plt.plot(logs_lr['epoch'],logs_lr['value'],marker='o')\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "IR_Implementation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0641a3de56591ccb311be5b58ba058515597b7ed8245473824ab72338b539668"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "034a9440e5514d8c99b71344108ebf2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04b8a8c40cfc4eb4987af7f0e52736c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30f45dd143564727b4c2859614795852",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bdecf506168f4d51847b928e23c0eb54",
      "value": 2
     }
    },
    "0607bc102e604876994c56479cc7ea2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "092190e7dd5e459db9e5b4b774a02ec8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ec63a50fbd049269e9c4eecb152e2cf",
      "placeholder": "",
      "style": "IPY_MODEL_d0da1ea81e5a4959a4785c4411292361",
      "value": "Downloading: 100%"
     }
    },
    "0998fb47b4844662aff81bf27b995d2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ec63a50fbd049269e9c4eecb152e2cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d17a2de1427404ab91551cb63a63b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc43b29e05c5492685a0454967fbcf7f",
      "placeholder": "",
      "style": "IPY_MODEL_51fda6fe16ac494598ff5cece064cb1f",
      "value": " 1.17k/1.17k [00:00&lt;00:00, 13.0kB/s]"
     }
    },
    "22548c8fe991408eb4dc440bf4c5fb35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a3e208e979ee41aaaf30adc62a060f41",
       "IPY_MODEL_2ef76ee0d4e44b53a275a24aeedc3b72",
       "IPY_MODEL_d349cc4b57234cde9610f1cbc090a4c1"
      ],
      "layout": "IPY_MODEL_607f07ee4e664ec5b100ddb298c6d91b"
     }
    },
    "276370695db3437a8e1df01ae1ce341a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d908770a619543f98722c8fe6c606792",
       "IPY_MODEL_870c08e73dec475a8eb870cb5de32740",
       "IPY_MODEL_1d17a2de1427404ab91551cb63a63b40"
      ],
      "layout": "IPY_MODEL_677b8b86db30437b80a0281d3780f632"
     }
    },
    "2ef76ee0d4e44b53a275a24aeedc3b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_442cc6d0066c4c44b66ff3edf269c855",
      "max": 242065649,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f1936d1022d4f3ca1050c0edf98b8f1",
      "value": 242065649
     }
    },
    "30f45dd143564727b4c2859614795852": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33552a1609e24bd69173b0302040534c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3734dfdad0164274a8c0b05b71a3ff77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37cea5acad284f3b962adaf6053b7232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37fbea390a194f70ab4b9910f11c41cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "442cc6d0066c4c44b66ff3edf269c855": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d4eaef3d4144bd9b9a838bab9230255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7006a50675a34b24ad9271a84bd5bdc8",
      "placeholder": "",
      "style": "IPY_MODEL_37cea5acad284f3b962adaf6053b7232",
      "value": " 773k/773k [00:00&lt;00:00, 910kB/s]"
     }
    },
    "4e628e0681454e02855a088042c08bb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4eab4e2d5aee4a919f0817024fcc4b8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "514a382acf2941c0af0a2844a6006b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37fbea390a194f70ab4b9910f11c41cc",
      "placeholder": "",
      "style": "IPY_MODEL_acd520a4d97d4fc29e5445fd168a84dc",
      "value": "Sanity Checking DataLoader 0: 100%"
     }
    },
    "51fda6fe16ac494598ff5cece064cb1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58c1590654a44b8f97f14b14a44fd436": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_514a382acf2941c0af0a2844a6006b4f",
       "IPY_MODEL_04b8a8c40cfc4eb4987af7f0e52736c2",
       "IPY_MODEL_853e69d805a84f80bb3cd252eda0ad6e"
      ],
      "layout": "IPY_MODEL_4eab4e2d5aee4a919f0817024fcc4b8b"
     }
    },
    "5f1936d1022d4f3ca1050c0edf98b8f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "607f07ee4e664ec5b100ddb298c6d91b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "677b8b86db30437b80a0281d3780f632": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "684f030cfcc44ce1a3621f0170860c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b1608a2b9954388ab9ba24d360653ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c7a83444b354148b147e5b2f0aa9c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_092190e7dd5e459db9e5b4b774a02ec8",
       "IPY_MODEL_ab6da49e288a4146a7b19b342df1f35a",
       "IPY_MODEL_4d4eaef3d4144bd9b9a838bab9230255"
      ],
      "layout": "IPY_MODEL_0607bc102e604876994c56479cc7ea2a"
     }
    },
    "7006a50675a34b24ad9271a84bd5bdc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "853e69d805a84f80bb3cd252eda0ad6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a32fe19d7784278bfd426d3114c8e24",
      "placeholder": "",
      "style": "IPY_MODEL_895dade65c4141bfb69dc491076827c3",
      "value": " 2/2 [00:00&lt;00:00,  2.11it/s]"
     }
    },
    "870c08e73dec475a8eb870cb5de32740": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89fc34e3829d46fb926bd16a3b1d82d3",
      "max": 1197,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3734dfdad0164274a8c0b05b71a3ff77",
      "value": 1197
     }
    },
    "895dade65c4141bfb69dc491076827c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89fc34e3829d46fb926bd16a3b1d82d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a32fe19d7784278bfd426d3114c8e24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3e208e979ee41aaaf30adc62a060f41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d30c1e610bec44d7a95abc86783c0117",
      "placeholder": "",
      "style": "IPY_MODEL_e0798eb9ff0d4adda3001e992bf8207e",
      "value": "Downloading: 100%"
     }
    },
    "ab6da49e288a4146a7b19b342df1f35a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0998fb47b4844662aff81bf27b995d2d",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b1608a2b9954388ab9ba24d360653ca",
      "value": 791656
     }
    },
    "acd520a4d97d4fc29e5445fd168a84dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc43b29e05c5492685a0454967fbcf7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdecf506168f4d51847b928e23c0eb54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d0da1ea81e5a4959a4785c4411292361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d30c1e610bec44d7a95abc86783c0117": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d349cc4b57234cde9610f1cbc090a4c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_034a9440e5514d8c99b71344108ebf2d",
      "placeholder": "",
      "style": "IPY_MODEL_33552a1609e24bd69173b0302040534c",
      "value": " 231M/231M [00:10&lt;00:00, 24.3MB/s]"
     }
    },
    "d908770a619543f98722c8fe6c606792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e628e0681454e02855a088042c08bb0",
      "placeholder": "",
      "style": "IPY_MODEL_684f030cfcc44ce1a3621f0170860c4e",
      "value": "Downloading: 100%"
     }
    },
    "e0798eb9ff0d4adda3001e992bf8207e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
